\section{Cache}
Cache serves as an intermediate memory buffer between the CPU and DRAM. It is faster than DRAM but much smaller in size.
In general, cache can save the same type of memory as is stored in DRAM.
\subsection{Principles}
\ptitle{Hits and Misses}

If the required memeory is found in cache the memory can be taken from there (\textbf{cache hit}, fast), else the memroy has to be loaded from DRAM (\textbf{cache miss}, slow).

\newpar{}
\ptitle{Locality}

The principles of locality are used to increase the cache hit rate:
\begin{itemize}
    \item \textbf{Principle of temporal locality (PTL)}:
          \begin{itemize}
              \item Information that was accessed recently, will likely be accessed soon again
              \item Example: variables in a for looop
          \end{itemize}
    \item \textbf{Priciple of spatial locality (PSL)}
          \begin{itemize}
              \item Information that is close in memory space, will be accessed together.
              \item Examples: Array, linked lists etc.\
          \end{itemize}
\end{itemize}

\subsection{Page Translation}
To decrease the computational cost arising from page table walks, a \textit{transitional lookaside buffer} can be used to store frequently accessed page table entries.

\subsubsection{Transitional Lookaside Buffer (TLB)}
\begin{itemize}
    \item TLB hit $\to$ return TLB entry (physical address)
    \item TLB miss $\to$ page table walk $\to$ save found physical page to TLB
\end{itemize}

\renewcommand{\arraystretch}{1.3}
\setlength{\oldtabcolsep}{\tabcolsep}\setlength\tabcolsep{9pt}

\begin{tabularx}{\linewidth}{@{}cc@{}}
    \multicolumn{2}{c}{\textbf{\code{TLB}}} \\
    \cmidrule{1-2}
    virt.\ address & phys.\ address         \\
    \cmidrule{1-2}
    $\vdots$       & $\vdots$               \\
    \cmidrule{1-2}
    virt.\ address & phys.\ address         \\
    \cmidrule{1-2}
\end{tabularx}

\renewcommand{\arraystretch}{1}
\setlength\tabcolsep{\oldtabcolsep}

\newpar{}
\ptitle{Eviction}

If the TLB is full entries can be evicted using the \textit{least recently used} (LRU) strategy. This strategy complies tih PTL.

\newpar{}
\textbf{Remark}
\begin{itemize}
    \item The TLB is only valid in one virtual address space, i.e.\ the TLB needs to be flushed explicity when changing vmas!
    \item Storing larger pages, i.e.\ huge pages in the TLB improves the coverage of the TLB. This idea is guided by PSL.
\end{itemize}

\subsection{Data/ Instruction Cache}

\subsubsection{Structure}
\ptitle{Cache Line Size}

In DDR4 a cache line has the size
\noindent\begin{equation*}
    \underbrace{8}_{\textsf{pipelines}}\cdot \underbrace{8~\mathrm{byte}}_{\textsf{request size}} = 64 ~\mathrm{byte}
\end{equation*}

\begin{itemize}
    \item \textbf{larger} cache lines would reduce the number of cache lines in the cache (violates PTL)
    \item \textbf{smaller} cache lines would reduce the number of data accessed at once (violates PSL)
\end{itemize}

\newpar{}
\textbf{Remark}
\begin{itemize}
    \item Cache is accesed with physical addresses to avoid flushing the cache when switching vmas
\end{itemize}

\subsubsection{Set-Associative Cache}
In set-associative cache, a DRAM entry can go to any slot in their set. The \textbf{wayness} is the number of entries per set (e.g. 4-way 4-set associative).

\newpar{}
\ptitle{Properties}
\begin{itemize}
    \item on typical workloads, most accesses do not cause eviction.
\end{itemize}

\ptitle{Extreme cases}
\begin{itemize}
    \item \textbf{Direct-mapped}: 1-way n-set associative.
    \item \textbf{Fully-associative}: n-way 1-set associative.
\end{itemize}

\paragraph{Direct Mapped Cache}
In direct-mapped cache, every slot of the cache can only map to one place in DRAM.
\newpar{}
The 64-bit cache line consists of
\begin{itemize}
    \item \textbf{Offset} within the cache line (6 bits: \fncode{cccccc})
    \item \textbf{Slot} (for 16/$2^4$ slots we need 4 bits: \fncode{ssss})
    \item \textbf{Tag} (22 bits: \fncode{tt..tt})
\end{itemize}
\includegraphics[width = \linewidth]{Cache.png}

\newpar{}
\ptitle{Properties}
\begin{itemize}
    \item[+] simple design
    \item[+] $\mathcal{O}(1)$
    \item[-] Sparse population
    \item[-] violating PTL
\end{itemize}

\paragraph{Fully-Assiociative Cache}
With fully-assiociative cache, every line from DRAM can go to every cache entry.

\newpar{}
The 64-bit cache line consists of
\begin{itemize}
    \item \textbf{Offset} within the cache line (6 bits: \fncode{cccccc})
    \item \textbf{Tag} (26 bits: \fncode{tt..tt})
\end{itemize}

\newpar{}
\ptitle{Properties}
\begin{itemize}
    \item[+] Flexible
    \item[+] Dense population
    \item[-] Many tag bits
    \item[-] Search through all tags
\end{itemize}

\subsubsection{Loading vs. Storing}
\ptitle{Loading}
\begin{itemize}
    \item If available, the memory can be read directly from cache
    \item Cached loads result in \textbf{clean} cache lines
\end{itemize}

\newpar{}
\ptitle{Storing}
\begin{itemize}
    \item Memory is first stored in cache alone, resulting in inconsistencies between cache and DRAM (\textbf{dirty} cache lines)
    \item On eviction
          \begin{itemize}
              \item \textbf{clean} cache lines can be discarded
              \item \textbf{dirty} cache lines need to be written to DRAM before discarding:
                    \begin{itemize}
                        \item \textbf{Write-back} policy:\newline write dirty cache line at \textbf{eviction time}
                        \item \textbf{write-through} policy:\newline write dirty cache line at \textbf{store time}
                        \item \textbf{Write-background} policy:\newline write dirty cache line in the \textbf{background}
                    \end{itemize}
          \end{itemize}
\end{itemize}