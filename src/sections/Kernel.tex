\section{Kernel}
\subsection{Memory Management}
\begin{itemize}
    \item Memory is usually DRAM (capacitory that need to be refreshed periodically)
    \item Last parallel bus (64/72 Bit) in modern computers
\end{itemize}


\subsubsection{Memory Sections}
\includegraphics[width = \linewidth]{memory_sections.png}

Kernel allocates code/stack at program start. Heap is allocated dynamically by the kernel and managed by the heap allocator library (e.g. \textit{heap.so}, part of application).

\ptitle{.text}

\begin{itemize}
    \item Generated by compiler
    \item Code (machine instructions)
    \item Does not change after the program ist written (except browser)
\end{itemize}


\ptitle{.data/.bss}

\begin{itemize}
    \item Generated by compiler
    \item \textit{.data}: initialized global vars, static function vars (sizes known beforehand)
    \item \textit{.bss}: same as above but not initialized: allocate a zero page and point to it (no physical memory usage)
\end{itemize}

\ptitle{Stack}

\begin{itemize}
    \item Compiler manages fixed-sized Stack
    \item Local variables, callee-saved registers, return address
\end{itemize}

\ptitle{Heap}
\begin{lstlisting}[language={C}]
    void *ptr = malloc(size_t);
    free(ptr);                  
\end{lstlisting}
\begin{itemize}
    \item User steers lifetime (new, delete)
    \item Available across functions
    \item Used also for large allocations
\end{itemize}

\subsubsection{Managing the Heap}
\begin{itemize}
    \item Heap suffers \textbf{fragmentation} at runtime: causes non-contiguous memory
          \noindent\begin{itemize}
              \item \textbf{External fragmentation} is caused by disadvantageous sequences of allocations/freeings (there would be enough free heap but it is not contiguous)
              \item \textbf{Internal fragmentation} is caused by having large heap units where small allocations waste memory
          \end{itemize}
    \item Fragmentation and finding free memory must be handeled
    \item \textbf{Heap metadata} are used to keep track of free memory and for sanity checks
          \noindent\begin{itemize}
              \item \textbf{In-band heap metadata} are stored inside the heap
              \item \textbf{Out-of-band heap metadata} are kept ouside the heap
          \end{itemize}
\end{itemize}

\paragraph{In-Band Metadata: Linked List}
\includegraphics[width = \linewidth]{free_linked_list.png}

\begin{itemize}
    \item Use a linked list to keep track of \textbf{free} heap sections
    \item Nodes stored at start of each free heap section
\end{itemize}

\begin{lstlisting}[language={C}]
typedef struct __node_t {
    int size;                           // allocation size
    union {
        int magic;                      // sanity check
        struct __node_t *next;          // next free section
    } u;
} node_t;         
\end{lstlisting}
\textbf{Remark}

A Union is used because either the \code{magic} value \textbf{or} the \code{*next} node is of interest.

\ptitle{Freeing Heap}

\begin{itemize}
    \item \lstinline{free(a)}
    \item Allocate a new \lstinline{__node_t} data structure
    \item Check if magic value has not been overwritten
    \item Let \lstinline{ __node_t *next} point to previous \lstinline{head}
    \item Make the new node the new \lstinline{head}
\end{itemize}

\ptitle{Selecting Free Heap}

\begin{itemize}
    \item Walk the linked list at \lstinline{malloc()} %ChkTex 36
          \begin{itemize}
              \item \textbf{First fit}: take first free slot that is big enough
              \item \textbf{Best fit}: take slot matching the required size the best (slow: walk entire list)
          \end{itemize}
    \item First fit uses space more efficiently than best fit (small losses at each allocation!)
    \item As slot is selected: remove corresponding node from list, update pointers, return pointer to free heap
\end{itemize}

\ptitle{Handling Fragmentation}

\begin{itemize}
    \item Coalesce/ combine the free list
    \item Walk the list, find adjacent free items and merge them
\end{itemize}

\paragraph[Bitmap-Based Allocations]{Out-Of-Band Metadata:\newline Bitmap-Based Allocations}
\begin{itemize}
    \item Every bit can tell whether $N$ bytes of the heap are free
    \item \code{malloc()} scans the bitmap for free space %ChkTex 36
    \item \code{free()} flips the right bits in the bitmap to zero %ChkTex 36
    \item One needs \textbf{additional} data to keep track of the total allocation sizes (as we only know status of our $N$ byte units)
\end{itemize}

\ptitle{Fragmentation vs. Performance}

\begin{itemize}
    \item Coalescing is very cheap (flipping bits)
    \item \code{malloc()} is more expensive (scan the bitmap), depending on how coarse the bitmap is %ChkTex 36
    \item In a \textbf{fine bitmap} one has precise allocations (low internal fragmentation) but expensive \code{malloc()} %ChkTex 36
    \item In a \textbf{coarse bitmap} one has more bytes per bit, hence less precise allocations (high internal frag) but cheap \lstinline{malloc()}
\end{itemize}


\paragraph{In-/Out-Of-Band Megadata: Slab Allocation}

\begin{itemize}
    \item Create ``sub-heaps'' (slabs) for common allocation sizes
    \item Each slab contains e.g. 12/16/256-byte entries
    \item Many implementations of slab allocators
    \item Applications'  allocators ask kernel for memory
    \item Kernel provides memory and can grow slabs if they are full or shrink them if empty
\end{itemize}

\ptitle{Pros and Cons}
\begin{itemize}
    \item[+] Flexible (various allocation sizes, growing/shrinking)
    \item[-] Fragmentation across slabs (not optimized for full utilization): can't move memory between slabs as they become full/empty
    \item Idea: use page allocation to move pages between different slabs
\end{itemize}
\paragraph{Page Allocation: Buddy Allocator}
Page Allocation optimizes for \textbf{full utilization}.
\begin{itemize}
    \item A page is a \textbf{contigous area of memory} aligned to the page size (4 KB)
    \item Blocks can have a size that scales with power-of-two wrt.\ the page size, this power is also called the \textbf{order}.
    \item Each page has a \textit{buddy} with the same size.
          \begin{itemize}
              \item If a page is split, a new page and a buddy with order - 1 are generated.
              \item If a page is freed and its buddy is also free, these two pages are merged into a page with order + 1
          \end{itemize}
\end{itemize}

\paragraph{Buddy Allocator: Interface}
\ptitle{\code{block\_alloc(order)}} %ChkTex 36
\begin{enumerate}
    \item if no block of \code{order} is available, split higher order block recursively.
    \item allocate block of desired \code{order}
\end{enumerate}

\begin{lstlisting}[style=bright_C++]
struct block *buddy_alloc(unsigned order)
{
    if (order > BUDDY_MAX_ORDER) return NULL;
    int smallest_order = __buddy_find_smallest_free_order(order);
    if (smallest_order == -1) return -1;

    int ret = buddy_split(smallest_order, order);
    if(ret == -2) return NULL;

    return buddy_pop(order);
}
\end{lstlisting}

\newpar{}
\ptitle{\code{block\_free(block)}} %ChkTex 36
\begin{enumerate}
    \item free block
    \item if buddy is free, merge into larger block
\end{enumerate}
\begin{lstlisting}[style=bright_C++]
int buddy_free(struct block *block)
{
    switch (block->refcnt) {
    case 0:
        return -1; /* Double free */
    case 1:
        buddy_push(block, block->order);
        __buddy_try_merge(block);

        return 0;
    default:
        block->refcnt--;
        return 0;
    }
}
\end{lstlisting}

\textbf{Remark} both \code{block\_alloc} and \code{block\_free} trigger a max of log(\code{max\_order}) of operations.

\paragraph{Buddy Allocator: Data Structures}
\ptitle{Block}
\begin{lstlisting}[style=bright_C++]
struct block {
    unsigned refcnt;
    unsigned order; /* 0 <= order <= BUDDY_MAX_ORDER */
    struct block *next;
};
\end{lstlisting}
\newpar{}
\begin{lstlisting}[style=bright_C++]
static struct block buddy_blocks[1UL << BUDDY_MAX_ORDER];
\end{lstlisting}

\ptitle{Free List}
\begin{lstlisting}[style=bright_C++]
static struct block *buddy_free_lists[BUDDY_MAX_ORDER + 1];
\end{lstlisting}

\paragraph{Buddy Allocator: Internal Functions}
\ptitle{Block to Buddy}
\begin{lstlisting}[style=bright_C++]
static inline struct block *block2buddy(struct block *block, int order)
{
    return __ppn2block(block2__ppn(block) ^ 1UL << order);
}
\end{lstlisting}

\newpar{}
\ptitle{Smallest Order}
\begin{lstlisting}[style=bright_C++]
static int __buddy_find_smallest_free_order(unsigned order)
{
    for (int i = order; i <= BUDDY_MAX_ORDER; i++) {
        if (!is_list_empty(i)) return i;
    }
    return -1;
}
\end{lstlisting}

\newpar{}
\ptitle{Push}

Push to the front of \code{buddy\_free\_lists}
\begin{lstlisting}[style=bright_C++]
static void buddy_push(struct block *block, unsigned order)
{
	block->next = buddy_free_lists[order];
	buddy_free_lists[order] = block;
	block->refcnt--;
}
\end{lstlisting}

\newpar{}
\ptitle{Pop}

Pop to the front of \code{buddy\_free\_lists}
\begin{lstlisting}[style=bright_C++]
static struct block *buddy_pop(unsigned order)
{
    if (is_list_empty(order)) return NULL;

    struct block *block = buddy_free_lists[order];

    /* update list and pop front of linked list */
	if (block->next != NULL) {
		buddy_free_lists[order] = block->next;
		block->next = NULL;
	} else {
		buddy_free_lists[order] = NULL;
	}
	block->refcnt++;

    return block;
}
\end{lstlisting}

\newpar{}
\ptitle{Remove}

Find \code{block} in  \code{buddy\_free\_lists} and \code{pop}.
\begin{lstlisting}[style=bright_C++]
static struct block *buddy_remove(struct block *block, unsigned order)
{
	if (is_list_empty(order)) return NULL;

	/* Find block in linked list and bring it to the front */
	if (buddy_free_lists[order] != block) {
		struct block *head = buddy_free_lists[order];
		struct block *tail = head;
		struct block *prev = NULL;

		while (tail->next) {
			if (tail->next == block) prev = tail;
			tail = tail->next;
		}

		if (!prev) return NULL; /* Could not find block */

		buddy_free_lists[order] = block;
		prev->next = NULL;
		tail->next = head;
	}

	return buddy_pop(order);
}
\end{lstlisting}

\newpar{}
\ptitle{Split}
\begin{lstlisting}[style=bright_C++]
static int buddy_split(unsigned smallest_free_order, unsigned desired_order)
{
	/* Will do nothing if smallest_free and desired are equal */
	for (int i = smallest_free_order; i > desired_order; i--) {
		int ret = __buddy_split(i);
		if (ret) return ret;
	}
	return 0;
}
\end{lstlisting}

\newpar{}
\begin{lstlisting}[style=bright_C++]
static int __buddy_split(unsigned order)
{
    if (order == 0) return -1;

    struct block *block = buddy_pop(order);

    if (!block) return -2; // no block available

    /* create buddy */
    block->order--;
    struct block *buddy = block2buddy(block, block->order);
    buddy->order = block->order;

    /* push split blocks to free lists */
    buddy_push(block, block->order);
    buddy_push(buddy, buddy->order);

    return 0;
}
\end{lstlisting}

\newpar{}
\ptitle{Merge}
\begin{lstlisting}[style=bright_C++]
static void __buddy_try_merge(struct block *block)
{
    if (block->order == BUDDY_MAX_ORDER) return;

    struct block *buddy = block2buddy(block, block->order);
    if (block->order != buddy->order) return;

    if (is_block_free(block) && is_block_free(buddy)) {
        block = __buddy_merge(block, buddy);
        __buddy_try_merge(block);
    }
}
\end{lstlisting}
\newpar{}
\begin{lstlisting}[style=bright_C++]
static struct block *__buddy_merge(struct block *block, struct block *buddy)
{
    /* Merge into the one with the smaller address */
    buddy_remove(buddy, buddy->order);
    buddy_remove(block, block->order);
    if (block2__ppn(block) < block2__ppn(buddy)) {
        block->order++;
        buddy_push(block, block->order);
        return block;

    } else {
        buddy->order++;
        buddy_push(buddy, buddy->order);
        return buddy;
    }
}
\end{lstlisting}

\subsection{Virtual Memory}
% Segmemtation and x86 history left out on purpose
With virtual memory, the users contigous memory is spread over in physical memory to improve flexibility and external fragmentation.
In order to achieve this, the memory management unit (\textbf{MMU}) translates memory addresses accordingly to create the illusion of contigous memory for the user.
\subsubsection{Segmentation}

\begin{itemize}
    \item Inflexible
    \item Suffers from both internal and external fragmentation
\end{itemize}

\subsubsection{Paging}
\begin{center}
    \includegraphics[width = \linewidth]{kernel_virt_mem.png}
\end{center}

\ptitle{Page Table}
\begin{itemize}
    \item translates the virtual page into a physical one
    \item In RISC-V, Pages have 4 KB (12 bit) granularity
    \item Kernel allocates pages (buddy)
    \item CPU's MMU translates addresses using the page table
\end{itemize}

\paragraph{Linear Page Table}
\begin{itemize}
    \item stored in CPU
    \item large unused parts (virtual >> physical)
    \item simple
\end{itemize}

\ptitle{Dimensions}
\noindent\begin{equation*}
    s_{\text{page table}} = n_{\text{virt}}\cdot (\log_2(n_{\text{phys}}) + 1)\quad [\text{bits}]
\end{equation*}

\renewcommand{\arraystretch}{1.3}
\setlength{\oldtabcolsep}{\tabcolsep}\setlength\tabcolsep{6pt}
\begin{tabularx}{\linewidth}{@{} c c c@{}}
                                                                                   & physical page                  & present bit \\
    \cmidrule{2-3}
    \multirow{7}{*}{\begin{sideways}$n_{\text{virt}}$\end{sideways}} & 10                             & 1           \\
                                                                                   & 01                             & 1           \\
                                                                                   & x                              & 0           \\
                                                                                   & x                              & 0           \\
                                                                                   & 00                             & 1           \\
                                                                                   & 11                             & 1           \\
                                                                                   & x                              & 0           \\
                                                                                   & x                              & 0           \\
    \cmidrule{2-3}
                                                                                   & $\log_2(n_{\text{phys}})$ bits &
\end{tabularx}

\paragraph{Multi-level Page Tables}
\begin{itemize}
    \item Pages are allocated when needed
    \item Stored im DRAM
    \item In our case (\textbf{Sv48}):
          \begin{itemize}
              \item 48 bit virtual and 56 bit physical address space
              \item 4-levels
              \item page table entry is 8 bytes (64 bit)
              \item page is 4 KB $\to$ 512 entries (9 bits) ($\frac{\text{4 KB}}{\text{8 B}}$)
              \item Virtual page number: 4 (levels) $\cdot$ 9 bits = 36 bits
          \end{itemize}
\end{itemize}

\begin{center}
    \includegraphics[width =\linewidth]{kernel_sv48.png}
\end{center}

\ptitle{Virtual $\to$ physical (memory walk)}
\begin{itemize}
    \item Done by CPU's MMU
\end{itemize}
\begin{center}
    \includegraphics[width = \linewidth]{kernel_ml_mem_walk.png}
\end{center}

\newpar{}
\ptitle{Creation}
\begin{itemize}
    \item Done in software (by OS)
    \item Identical to memory walk.
    \item If \code{present == 0}, allocate new page (\code{buddy\_alloc(0)} $\to$ \code{ppn}) and update PPN.\ %ChkTeX 36
\end{itemize}

\newcol{}
\ptitle{Page Table Entry}

\begin{center}
    \includegraphics[width = \linewidth]{kernel_page_entry.png}
\end{center}

\renewcommand{\arraystretch}{1.3}
\setlength{\oldtabcolsep}{\tabcolsep}\setlength\tabcolsep{6pt}
\begin{tabularx}{\linewidth}{@{}llcll@{}}
    V & valid     &  & G    & accessed \\
    R & read      &  & D    & dirty    \\
    W & write     &  & PBMT & IO       \\
    X & execute   &  & N    & TLBOPT   \\
    U & user mode &  &
\end{tabularx}

\begin{tabularx}{\linewidth}{@{}cccl@{}}
    X & W & R & Meaning                             \\
    \cmidrule{1-4}
    0 & 0 & 0 & Pointer to next level of page table \\
    0 & 0 & 1 & Read-only page                      \\
    0 & 1 & 0 & Reserved for future use             \\
    0 & 1 & 1 & Read-write page                     \\
    1 & 0 & 0 & Execute-only page                   \\
    1 & 0 & 1 & Read-execute page                   \\
    1 & 1 & 0 & Reserved for future use             \\
    1 & 1 & 1 & Read-write-execute page
\end{tabularx}
\renewcommand{\arraystretch}{1}
\setlength\tabcolsep{\oldtabcolsep}

\newpar{}
\ptitle{satp}
\begin{itemize}
    \item \code{satp} register points to the root of the page table
\end{itemize}
\begin{center}
    \includegraphics[width = \linewidth]{kernel_satp.png}
\end{center}
\begin{center}
    \includegraphics[width = .6\linewidth]{kernel_satp_table.png}
\end{center}