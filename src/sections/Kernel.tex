\section{Kernel}
\subsection{Memory Management}
\begin{itemize}
    \item Memory is usually DRAM (capacitory that need to be refreshed periodically)
    \item Last parallel bus (64/72 Bit) in modern computers
\end{itemize}


\subsubsection{Memory Sections}
\includegraphics[width = \linewidth]{memory_sections.png}

Kernel allocates code/stack at program start. Heap is allocated dynamically by the kernel and managed by the heap allocator library (e.g. \textit{heap.so}, part of application).

\ptitle{.text}

\begin{itemize}
    \item Generated by compiler
    \item Code (machine instructions)
    \item Does not change after the program ist written (except browser)
\end{itemize}


\ptitle{.data/.bss}

\begin{itemize}
    \item Generated by compiler
    \item \textit{.data}: initialized global vars, static function vars (sizes known beforehand)
    \item \textit{.bss}: same as above but not initialized: allocate a zero page and point to it (no physical memory usage)
\end{itemize}

\ptitle{Stack}

\begin{itemize}
    \item Compiler manages fixed-sized Stack
    \item Local variables, callee-saved registers, return address
\end{itemize}

\ptitle{Heap}
\begin{lstlisting}[language={C}]
    void *ptr = malloc(size_t);
    free(ptr);                  
\end{lstlisting}
\begin{itemize}
    \item User steers lifetime (new, delete)
    \item Available across functions
    \item Used also for large allocations
\end{itemize}

\subsubsection{Managing the Heap}
\begin{itemize}
    \item Heap suffers \textbf{fragmentation} at runtime: causes non-contiguous memory
          \noindent\begin{itemize}
              \item \textbf{External fragmentation} is caused by disadvantageous sequences of allocations/freeings (there would be enough free heap but it is not contiguous)
              \item \textbf{Internal fragmentation} is caused by having large heap units where small allocations waste memory
          \end{itemize}
    \item Fragmentation and finding free memory must be handeled
    \item \textbf{Heap metadata} are used to keep track of free memory and for sanity checks
          \noindent\begin{itemize}
              \item \textbf{In-band heap metadata} are stored inside the heap
              \item \textbf{Out-of-band heap metadata} are kept ouside the heap
          \end{itemize}
\end{itemize}

\paragraph{In-Band Metadata: Linked List}
\includegraphics[width = \linewidth]{free_linked_list.png}

\begin{itemize}
    \item Use a linked list to keep track of \textbf{free} heap sections
    \item Nodes stored at start of each free heap section
\end{itemize}

\begin{lstlisting}[language={C}]
typedef struct __node_t {
    int size;                           // allocation size
    union {
        int magic;                      // sanity check
        struct __node_t *next;          // next free section
    } u;
} node_t;         
\end{lstlisting}
\textbf{Remark}

A Union is used because either the \code{magic} value \textbf{or} the \code{*next} node is of interest.

\ptitle{Freeing Heap}

\begin{itemize}
    \item \lstinline{free(a)}
    \item Allocate a new \lstinline{__node_t} data structure
    \item Check if magic value has not been overwritten
    \item Let \lstinline{ __node_t *next} point to previous \lstinline{head}
    \item Make the new node the new \lstinline{head}
\end{itemize}

\ptitle{Selecting Free Heap}

\begin{itemize}
    \item Walk the linked list at \lstinline{malloc()} %ChkTex 36
          \begin{itemize}
              \item \textbf{First fit}: take first free slot that is big enough
              \item \textbf{Best fit}: take slot matching the required size the best (slow: walk entire list)
          \end{itemize}
    \item First fit uses space more efficiently than best fit (small losses at each allocation!)
    \item As slot is selected: remove corresponding node from list, update pointers, return pointer to free heap
\end{itemize}

\ptitle{Handling Fragmentation}

\begin{itemize}
    \item Coalesce/ combine the free list
    \item Walk the list, find adjacent free items and merge them
\end{itemize}

\paragraph[Bitmap-Based Allocations]{Out-Of-Band Metadata:\newline Bitmap-Based Allocations}
\begin{itemize}
    \item Every bit can tell whether $N$ bytes of the heap are free
    \item \code{malloc()} scans the bitmap for free space %ChkTex 36
    \item \code{free()} flips the right bits in the bitmap to zero %ChkTex 36
    \item One needs \textbf{additional} data to keep track of the total allocation sizes (as we only know status of our $N$ byte units)
\end{itemize}

\ptitle{Fragmentation vs. Performance}

\begin{itemize}
    \item Coalescing is very cheap (flipping bits)
    \item \code{malloc()} is more expensive (scan the bitmap), depending on how coarse the bitmap is %ChkTex 36
    \item In a \textbf{fine bitmap} one has precise allocations (low internal fragmentation) but expensive \code{malloc()} %ChkTex 36
    \item In a \textbf{coarse bitmap} one has more bytes per bit, hence less precise allocations (high internal frag) but cheap \lstinline{malloc()}
\end{itemize}


\paragraph{In-/Out-Of-Band Megadata: Slab Allocation}

\begin{itemize}
    \item Create ``sub-heaps'' (slabs) for common allocation sizes
    \item Each slab contains e.g. 12/16/256-byte entries
    \item Many implementations of slab allocators
    \item Applications'  allocators ask kernel for memory
    \item Kernel provides memory and can grow slabs if they are full or shrink them if empty
\end{itemize}

\ptitle{Pros and Cons}
\begin{itemize}
    \item[+] Flexible (various allocation sizes, growing/shrinking)
    \item[-] Fragmentation across slabs (not optimized for full utilization): can't move memory between slabs as they become full/empty
    \item Idea: use page allocation to move pages between different slabs
\end{itemize}
\paragraph{Page Allocation: Buddy Allocator}
Page Allocation optimizes for \textbf{full utilization}.
\begin{itemize}
    \item A page is a \textbf{contigous area of memory} aligned to the page size (4 KB)
    \item Blocks can have a size that scales with power-of-two wrt.\ the page size, this power is also called the \textbf{order}.
    \item Each page has a \textit{buddy} with the same size.
          \begin{itemize}
              \item If a page is split, a new page and a buddy with order - 1 are generated.
              \item If a page is freed and its buddy is also free, these two pages are merged into a page with order + 1
          \end{itemize}
\end{itemize}

\paragraph{Buddy Allocator: Interface}
\ptitle{\code{block\_alloc(order)}} %ChkTex 36
\begin{enumerate}
    \item if no block of \code{order} is available, split higher order block recursively.
    \item allocate block of desired \code{order}
\end{enumerate}

\begin{lstlisting}[style=bright_C++]
struct block *buddy_alloc(unsigned order)
{
    if (order > BUDDY_MAX_ORDER) return NULL;
    int smallest_order = __buddy_find_smallest_free_order(order);
    if (smallest_order == -1) return -1;

    int ret = buddy_split(smallest_order, order);
    if(ret == -2) return NULL;

    return buddy_pop(order);
}
\end{lstlisting}

\newpar{}
\ptitle{\code{block\_free(block)}} %ChkTex 36
\begin{enumerate}
    \item free block
    \item if buddy is free, merge into larger block
\end{enumerate}
\begin{lstlisting}[style=bright_C++]
int buddy_free(struct block *block)
{
    switch (block->refcnt) {
    case 0:
        return -1; /* Double free */
    case 1:
        block->refcnt--;
        buddy_push(block, block->order);
        __buddy_try_merge(block);

        return 0;
    default:
        block->refcnt--;
        return 0;
    }
}
\end{lstlisting}

\textbf{Remark} both \code{block\_alloc} and \code{Block\_free} trigger a max of log(\code{max\_order}) of operations.

\paragraph{Buddy Allocator: Data Structures}
\ptitle{Block}
\begin{lstlisting}[style=bright_C++]
struct block {
    unsigned refcnt;
    unsigned order; /* 0 <= order <= BUDDY_MAX_ORDER */
    struct block *next;
};
\end{lstlisting}
\newpar{}
\begin{lstlisting}[style=bright_C++]
static struct block buddy_blocks[1UL << BUDDY_MAX_ORDER];
\end{lstlisting}

\ptitle{Free List}
\begin{lstlisting}[style=bright_C++]
static struct block *buddy_free_lists[BUDDY_MAX_ORDER + 1];
\end{lstlisting}

\paragraph{Buddy Allocator: Internal Functions}
\ptitle{Block to Buddy}
\begin{lstlisting}[style=bright_C++]
#define block2buddy(block, order) \
        (__ppn2block(block2__ppn(block) ^ 1UL << order))
\end{lstlisting}

\newpar{}
\ptitle{Smallest Order}
\begin{lstlisting}[style=bright_C++]
static int __buddy_find_smallest_free_order(unsigned order)
{
    for (int i = order; i <= BUDDY_MAX_ORDER; i++) {
        if (!is_list_empty(i)) return i;
    }
    return -1;
}
\end{lstlisting}

\newpar{}
\ptitle{Push}

Push to the front of \code{buddy\_free\_lists}
\begin{lstlisting}[style=bright_C++]
static void buddy_push(struct block *block, unsigned order)
{
    block->refcnt = 0;
    block->next = buddy_free_lists[order];
    buddy_free_lists[order] = block;
}
\end{lstlisting}

\newpar{}
\ptitle{Pop}

Pop to the front of \code{buddy\_free\_lists}
\begin{lstlisting}[style=bright_C++]
static struct block *buddy_pop(unsigned order)
{
    if (is_list_empty(order)) return NULL;

    struct block *block = buddy_free_lists[order];

    /* update list and remove from linked list */
    block->refcnt = 1;
    if (block->next != NULL) {
        buddy_free_lists[order] = block->next;
        block->next = NULL;
    } else {
        buddy_free_lists[order] = NULL;
    }

    return block;
}
\end{lstlisting}

\newpar{}
\ptitle{Remove}

Find \code{block} in  \code{buddy\_free\_lists} and \code{pop}.
\begin{lstlisting}[style=bright_C++]
static struct block *buddy_remove(struct block *block, unsigned order)
{
	if (is_list_empty(order)) return NULL;

	/* Find block in linked list and bring it to the front */
	if (buddy_free_lists[order] != block) {
		struct block *head = buddy_free_lists[order];
		struct block *tail = head;
		struct block *prev = NULL;

		while (tail->next) {
			if (tail->next == block) prev = tail;
			tail = tail->next;
		}

		if (!prev) return NULL; /* Could not find block */

		buddy_free_lists[order] = block;
		prev->next = NULL;
		tail->next = head;
	}

	return buddy_pop(order);
}
\end{lstlisting}

\newpar{}
\ptitle{Split}
\begin{lstlisting}[style=bright_C++]
static int buddy_split(unsigned smallest_free_order, unsigned desired_order)
{
	/* Will do nothing if smallest_free and desired are equal */
	for (int i = smallest_free_order; i > desired_order; i--) {
		int ret = __buddy_split(i);
		if (ret) return ret;
	}
	return 0;
}
\end{lstlisting}

\newpar{}
\begin{lstlisting}[style=bright_C++]
static int __buddy_split(unsigned order)
{
    if (order == 0) return -1;

    struct block *block = buddy_pop(order);

    if (!block) return -2; // no block available

    /* create buddy */
    block->order--;
    struct block *buddy = block2buddy(block, block->order);
    buddy->order = block->order;

    /* push split blocks to free lists */
    buddy_push(block, block->order);
    buddy_push(buddy, buddy->order);

    return 0;
}
\end{lstlisting}

\newpar{}
\ptitle{Merge}
\begin{lstlisting}[style=bright_C++]
static void __buddy_try_merge(struct block *block)
{
    if (block->order == BUDDY_MAX_ORDER) return;

    struct block *buddy = block2buddy(block, block->order);
    if (block->order != buddy->order) return;

    if (is_block_free(block) && is_block_free(buddy)) {
        block = __buddy_merge(block, buddy);
        __buddy_try_merge(block);
    }
}
\end{lstlisting}
\newpar{}
\begin{lstlisting}[style=bright_C++]
static struct block *__buddy_merge(struct block *block, struct block *buddy)
{
    /* Merge into the one with the smaller address */
    buddy_remove(buddy, buddy->order);
    buddy_remove(block, block->order);
    if (block2__ppn(block) < block2__ppn(buddy)) {
        block->order++;
        buddy_push(block, block->order);
        return block;

    } else {
        buddy->order++;
        buddy_push(buddy, buddy->order);
        return buddy;
    }
}
\end{lstlisting}

